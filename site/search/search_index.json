{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Features Speech Recognition Engine without connection to cloud or external server. Ultra low latency recognition that can reach down to less than 100ms. Remove the requirement of wake-up word for every command. Enable local training of the model and fine-tune it for individual voices. Provide an environment for recording samples and verifying the recorded audio data. Achieve 99% accuracy thanks to the small set of words and adapt to the user's accent. Offer full customization of the word list and control over the training setup. Provide easy integration with other softwares through DBus (Linux) and Named-Pipe (Windows) platform. Allow voice control interface for Windows 10 and Linux running with custom setup of Awesome-WM and Polybar . Ready to use product without any requirement for customization and coding skill. Origin of Design Benjamin began as a voice control interface to control a PC without any interaction through hands. numerous other products exist on the market, offering specific application solutions. What sets Benjamin apart from these projects is its tailored design for individuals with handicap to use this system to interact with a PC all day long. This requirement stress over highest level of accuracy and focus on decreasing latency as many command and control actions require quick response time. One notable product for comparison is the Google Speech Recognition Engine integrated into YouTube's subtitle generator. This engine prioritizes accuracy across a diverse range of accents found in the general population. However, if user accent is a minority, the accuracy will compromise. Another critical assumption in the YouTube ASR engine is the availability of future voice data ( non causal ), with no stringent requirement on output latency. This drastically alters the architecture of ASR engine design to maximize the accuracy. Benjamin addresses these challenges by decreasing the number of words in the vocabulary and focus on single person's accent rather than general public to achieve same or better accuracy than major ASR engines, while maintaining low latency output.It aims to provide users in need of creating a voice control software a better starting point so hopefully in future we will see more progress in future of robust ASR engines and voice control softwares for this specific application.","title":"Home"},{"location":"#features","text":"Speech Recognition Engine without connection to cloud or external server. Ultra low latency recognition that can reach down to less than 100ms. Remove the requirement of wake-up word for every command. Enable local training of the model and fine-tune it for individual voices. Provide an environment for recording samples and verifying the recorded audio data. Achieve 99% accuracy thanks to the small set of words and adapt to the user's accent. Offer full customization of the word list and control over the training setup. Provide easy integration with other softwares through DBus (Linux) and Named-Pipe (Windows) platform. Allow voice control interface for Windows 10 and Linux running with custom setup of Awesome-WM and Polybar . Ready to use product without any requirement for customization and coding skill.","title":"Features"},{"location":"#origin-of-design","text":"Benjamin began as a voice control interface to control a PC without any interaction through hands. numerous other products exist on the market, offering specific application solutions. What sets Benjamin apart from these projects is its tailored design for individuals with handicap to use this system to interact with a PC all day long. This requirement stress over highest level of accuracy and focus on decreasing latency as many command and control actions require quick response time. One notable product for comparison is the Google Speech Recognition Engine integrated into YouTube's subtitle generator. This engine prioritizes accuracy across a diverse range of accents found in the general population. However, if user accent is a minority, the accuracy will compromise. Another critical assumption in the YouTube ASR engine is the availability of future voice data ( non causal ), with no stringent requirement on output latency. This drastically alters the architecture of ASR engine design to maximize the accuracy. Benjamin addresses these challenges by decreasing the number of words in the vocabulary and focus on single person's accent rather than general public to achieve same or better accuracy than major ASR engines, while maintaining low latency output.It aims to provide users in need of creating a voice control software a better starting point so hopefully in future we will see more progress in future of robust ASR engines and voice control softwares for this specific application.","title":"Origin of Design"},{"location":"About/","text":"About Feel free to contact us by sending email.","title":"About"},{"location":"About/#about","text":"Feel free to contact us by sending email.","title":"About"},{"location":"Additional-Commands/","text":"--|--","title":"Additional Commands"},{"location":"Capture-Audio-Samples/","text":"User Guide Quick Start ArBade has many tabs, explained in the following. To change tab click or press numbers on keyboard starting from 1. ArBade is a shortcut based application. Shortcuts are listed in the application topbar. To see all shortcuts, press / . First step is to train a model from your voice. Record Samples specify a category name by pressing S . category name is used to distinguish between speaker or microphone. Start to record by pressing space . Say the words specified between <> while status is Rec . You can pause the Record procedure any time by using space and get out of record panel by pressing Escape . Then Statistics will be updated. Arbitrary name of category. Record list showing the samples recorded. Word list showing how many samples include the specific word. sample count in specific category. Detailed description about record parameters and procedure can be found in the User Guide","title":"Capture Audio Samples"},{"location":"Capture-Audio-Samples/#user-guide","text":"","title":"User Guide"},{"location":"Capture-Audio-Samples/#quick-start","text":"ArBade has many tabs, explained in the following. To change tab click or press numbers on keyboard starting from 1. ArBade is a shortcut based application. Shortcuts are listed in the application topbar. To see all shortcuts, press / . First step is to train a model from your voice.","title":"Quick Start"},{"location":"Capture-Audio-Samples/#record-samples","text":"specify a category name by pressing S . category name is used to distinguish between speaker or microphone. Start to record by pressing space . Say the words specified between <> while status is Rec . You can pause the Record procedure any time by using space and get out of record panel by pressing Escape . Then Statistics will be updated. Arbitrary name of category. Record list showing the samples recorded. Word list showing how many samples include the specific word. sample count in specific category. Detailed description about record parameters and procedure can be found in the User Guide","title":"Record Samples"},{"location":"Controlling-Keyboard/","text":"Command Action Command Action arch a november n bravo b oscar o catalina c papa p delta d quebec q echo e romeo r fish f sierra s golf g tango t hotel h u u india i vpn v jordan j wake w kilo k eggs x limo l yankee y mike m zed z Command Action Command Action sim Space plus + end end slash / home home canals \\ semi ; edge Menu key period . bracket [] comma , curly {} dash - quote \"\" level = github Caps lock","title":"Controlling Keyboard"},{"location":"Controlling-Mouse/","text":"Command Action Description Mouse Left Left Click Mouse Right Right Click Mouse M Middle Click Mouse Up Scroll Up Mouse Down Scroll Down Mouse P Primary Monitor Mouse S Secondary Monitor Mouse L Primary Monitor Left Side Mouse R Primary Monitor Right Side Mouse U Scroll Up 4 Times Mouse D Scroll Down 4 Times Mouse G Scroll Up 6 Times Mouse H Scroll Down 6 Times In the following image you can see chess in action. Chess supports following commands: Kick : Normal left click button Side : Right click button Drag : Drag with left click between two points. System Sierra : Take screenshot between two points and put it in clipboard Comments : Open chess on second monitor","title":"Controlling Mouse"},{"location":"First-Time-Bring-Up/","text":"BaTool is a real-time speech recognition engine, that gets a triphone Kaldi model and do a low latency speech recognition on the data coming from the system default microphone. BaTool Conf Batool is configurable via conf file next to BaTool application. It has 4 main sections to configure: Model Section: This section defines the location of Kaldi model files. The addresses are relative to where BaTool application exists. ; Model path [model] fst = \"Model/HCLG.fst\" mdl = \"Model/final.oalimdl\" word = \"Model/words.txt\" cmvn = \"Model/global_cmvn.stats\" Decoder Section: Kaldi related decoder settings. max_active = 900 min_active = 200 train_max = 5 ac_scale = 0.05 min_sil = 20 train_max : Maximum number of same samples for later training. min_sil : Minimum silence before detection. This value directly connected with accuracy and latency. Topbar Mom is like PolyBar , it manages different workspace, shows system status and BaTool detection output. Mom is named after the fact that it will spawn all the child applications (BaTool, Chess, Rebound). Mom reads BaTool detection from Benjamin/Mom/Labels with PolyBar Application format . Mom has several widgets: Workspaces: you can switch between 6 workspaces showed with different icons. Word detection from BaTool and ENN . Date and time Music widget: Used to pause/play music. Also go to next/previous music. CPU usage Speaker: By clicking on this icon you can alter between speaker and headphone. By scrolling you can increase/decrease the volume. Focused application System status: Shows if system is running or sleeping or halted. Color of detected word is set by ENN application and sorted from best detection accuracy to worst: Best Good Lowest Confidence Wrong","title":"First Time Bring-up"},{"location":"First-Time-Bring-Up/#batool-conf","text":"Batool is configurable via conf file next to BaTool application. It has 4 main sections to configure:","title":"BaTool Conf"},{"location":"First-Time-Bring-Up/#model-section","text":"This section defines the location of Kaldi model files. The addresses are relative to where BaTool application exists. ; Model path [model] fst = \"Model/HCLG.fst\" mdl = \"Model/final.oalimdl\" word = \"Model/words.txt\" cmvn = \"Model/global_cmvn.stats\"","title":"Model Section:"},{"location":"First-Time-Bring-Up/#decoder-section","text":"Kaldi related decoder settings. max_active = 900 min_active = 200 train_max = 5 ac_scale = 0.05 min_sil = 20 train_max : Maximum number of same samples for later training. min_sil : Minimum silence before detection. This value directly connected with accuracy and latency.","title":"Decoder Section:"},{"location":"First-Time-Bring-Up/#topbar","text":"Mom is like PolyBar , it manages different workspace, shows system status and BaTool detection output. Mom is named after the fact that it will spawn all the child applications (BaTool, Chess, Rebound). Mom reads BaTool detection from Benjamin/Mom/Labels with PolyBar Application format . Mom has several widgets: Workspaces: you can switch between 6 workspaces showed with different icons. Word detection from BaTool and ENN . Date and time Music widget: Used to pause/play music. Also go to next/previous music. CPU usage Speaker: By clicking on this icon you can alter between speaker and headphone. By scrolling you can increase/decrease the volume. Focused application System status: Shows if system is running or sleeping or halted. Color of detected word is set by ENN application and sorted from best detection accuracy to worst: Best Good Lowest Confidence Wrong","title":"Topbar"},{"location":"Installation/","text":"Warning At the moment Benjamin-ASR prioritizes enabling user and increase the productivity. Unfortunately due to lack of resources, security receiving less attention. Therefore, it is not advisable to install this software on end-user machines where security is a concern. Requirements Operating system: Windows 10 22H2, Windows 11 21H2 Access level: Need administrator user account with disabled UAC CPU: Intel I5 10500 RAM: 2 GB GPU: Not required Windows Install Firefox Developer Edition: Firefox-Dev_120.0b1.exe Info Firefox only allows extensions that are signed by Mozilla to be installed in firefox since version 92. Unfortunately we don't like their ideas of monopoly on web extensions and the hassle of sending code each time to Mozilla and waiting for them to sign. To bypass this feature, the only way is to install firefox developer edition. Hint Our extension is open sourced and not obfuscated, so you are always welcome to review it by yourself raise any comments in GitHub issues. Install extension Download Benjfox.xpi extension Open Firefox, press Ctrl+Shift+A to open Add-on page. Click on the settings icon and select Install Add-on From File . Select xpi file and install. Info Firefox extension only needed to facilitate scrolling up and down through voice command. You can totally skip step 1 and 2, if you don't need this functionality. Install Benjamin-ASR: Benjamin-ASR.exe","title":"Installation"},{"location":"Installation/#requirements","text":"Operating system: Windows 10 22H2, Windows 11 21H2 Access level: Need administrator user account with disabled UAC CPU: Intel I5 10500 RAM: 2 GB GPU: Not required","title":"Requirements"},{"location":"Installation/#windows","text":"Install Firefox Developer Edition: Firefox-Dev_120.0b1.exe Info Firefox only allows extensions that are signed by Mozilla to be installed in firefox since version 92. Unfortunately we don't like their ideas of monopoly on web extensions and the hassle of sending code each time to Mozilla and waiting for them to sign. To bypass this feature, the only way is to install firefox developer edition. Hint Our extension is open sourced and not obfuscated, so you are always welcome to review it by yourself raise any comments in GitHub issues. Install extension Download Benjfox.xpi extension Open Firefox, press Ctrl+Shift+A to open Add-on page. Click on the settings icon and select Install Add-on From File . Select xpi file and install. Info Firefox extension only needed to facilitate scrolling up and down through voice command. You can totally skip step 1 and 2, if you don't need this functionality. Install Benjamin-ASR: Benjamin-ASR.exe","title":"Windows"},{"location":"Quick-Start-Guide/","text":"Overview Here are the steps you need to take to make Benjamin-ASR operational. Typically, it takes about a week to record all the required samples to make a fully functional model. However in less than an hour, you should be able to create a small demo model to checkout the accuracy and get an idea of the whole process. 1. Decide on Your Wordlist: less than 20 mins First you need to decide if you want to train a full model or just a demo model. Training a full model requires significantly more time, therefore if you are a new user, it is recommended to start with a demo model. Demo Case: Keep all the numbers from zero to nine, remove all the words in the vocabulary. Default Case: No changes need to be made. Customized Case: Add or remove words as you please. However keep in mind that to achieve decent performance from the engine, you need to train Count^2 times, where Count represents the number of words in your word list. 2. Record Audio Samples: 1hr / 1week Hint The number of samples depend on the user but generally the more the merrier. For the small demo model 400 samples should be enough. However for full functional model usually at least 5K samples is needed. Sample means an audio .wav file consisted of three spoken words. 3. Train a Model: 30 mins Open Trainer and train a model. 4. Learn How to Use and Improve the Model Next step is to learn how to control mouse and keyboard and special features Benjamin provides to ease use of common application like Firefox, Slack and ... . Benjamin also records all the samples while you use the software so you can later train on these samples too.","title":"Quick Start Guide"},{"location":"Quick-Start-Guide/#overview","text":"Here are the steps you need to take to make Benjamin-ASR operational. Typically, it takes about a week to record all the required samples to make a fully functional model. However in less than an hour, you should be able to create a small demo model to checkout the accuracy and get an idea of the whole process. 1. Decide on Your Wordlist: less than 20 mins First you need to decide if you want to train a full model or just a demo model. Training a full model requires significantly more time, therefore if you are a new user, it is recommended to start with a demo model. Demo Case: Keep all the numbers from zero to nine, remove all the words in the vocabulary. Default Case: No changes need to be made. Customized Case: Add or remove words as you please. However keep in mind that to achieve decent performance from the engine, you need to train Count^2 times, where Count represents the number of words in your word list. 2. Record Audio Samples: 1hr / 1week Hint The number of samples depend on the user but generally the more the merrier. For the small demo model 400 samples should be enough. However for full functional model usually at least 5K samples is needed. Sample means an audio .wav file consisted of three spoken words. 3. Train a Model: 30 mins Open Trainer and train a model. 4. Learn How to Use and Improve the Model Next step is to learn how to control mouse and keyboard and special features Benjamin provides to ease use of common application like Firefox, Slack and ... . Benjamin also records all the samples while you use the software so you can later train on these samples too.","title":"Overview"},{"location":"Rebound/","text":"Rebound","title":"Rebound"},{"location":"Rebound/#rebound","text":"","title":"Rebound"},{"location":"Train-Model/","text":"Now if you have enough samples, you can train your model by Pressing T . At any time outside of terminal, by pressing P or clicking on Console tab, you can access the results of running train scripts in terminal. All the train procedure is automatic and you should only wait for the dialog indicating train is finished and now it's ENN samples generation turn. And verifying engine false generated samples. Detailed description about train steps and procedure can be found in User Guide Verification When you are using Benjamin regularly, samples will be generated when issueing commands or recorded when in sleep mode saying ordinary words. To use these samples, you need to assure that they are matched with the detected words. For verifying these samples you can switch to Verify tab and press space to start verification process. While verifying sleep mode samples, make sure that all words are detected wrong. Verifying If the sample is wrong press Z to delete sample, while playing or at Decide Pause status after voice stopped. By default after playing each sample in unverified category, if there wasn't any key press, the sample will be verified. you can change this behaviour by pressing R . Detailed description about verification parameters and procedure can be found in User Guide Congrats! Now you know the very initial steps to train your model!","title":"Train Model"},{"location":"Train-Model/#verification","text":"When you are using Benjamin regularly, samples will be generated when issueing commands or recorded when in sleep mode saying ordinary words. To use these samples, you need to assure that they are matched with the detected words. For verifying these samples you can switch to Verify tab and press space to start verification process. While verifying sleep mode samples, make sure that all words are detected wrong. Verifying If the sample is wrong press Z to delete sample, while playing or at Decide Pause status after voice stopped. By default after playing each sample in unverified category, if there wasn't any key press, the sample will be verified. you can change this behaviour by pressing R . Detailed description about verification parameters and procedure can be found in User Guide Congrats! Now you know the very initial steps to train your model!","title":"Verification"},{"location":"Train-Neural-Network/","text":"ENN ENN generates neural network model from ENN samples. ENN samples are cepstrums that were normalized and aligned to a single word saved as a simple 40x40 binary array. we feed this to a convolutional neural network followed by a fully connected layer to detect out of vocabulary words. ENN is an optional feature that brings more accuracy and let you leave the system on always, so you dont need to say wake up words. ENN user interface includes these main tabs: Train Sample Link Wrong ENN Train In Train Tab you can watch the learning procedure of each word. In train Panel, learning loss and test loss is shown for first 4 words in wordlist panel. You can watch other word loss plots by pressing Up/Down arrow keys on keyboard. Hover on each word in word list panel to see how many samples are trained from total samples. Also you can sort the model statistics based on train precision, test precision and loss by clicking relevant table header (to reset the sort method click on ID header). Learned models will be saved in Model directory. Parameters Thread Num: Number of concurrent words to learn. (Be careful to set it lower than your number of CPU cores to prevent windows freeze) Learning rate: Base learning rate for each word to start training. Target Loss: Loss that model is considered learned. Param Num: Number of parameters the model has to learn. True Count: Number of ENN samples in enn/true directory. False Count: Number of ENN samples in enn/false directory. Learned Count: Number of words that their loss become less than target loss. Loop Count: Training for each word takes 200 epoch, if target loss not reached. Then next word's training procedure starts. After all words training finished, program will start from first word and increases loop count. Train Time: Time that program is training words. ENN Sample Link In sample link tab all true sample cepstrums are ploted in images. In this way you can find out why training for a word has large loss and not reaches the target loss. By using direction arrow keys you can select then play the wave related to each sample. Also change the word to see its samples. (Train procedure is not stopped while sample link is active) Wrong In training procedure, some samples couldn't be learned, they will be stored in Models/Wrong directory. For each model there is a relevant .wrong file that is filled by all failed samples. In the same way as Sample Link you can watch wrong detected sample cepstrums and here relevant recorded wave. The label for each sample is shown in right bottom corner of its cepstrum.","title":"Train Neural Network"},{"location":"Train-Neural-Network/#enn","text":"ENN generates neural network model from ENN samples. ENN samples are cepstrums that were normalized and aligned to a single word saved as a simple 40x40 binary array. we feed this to a convolutional neural network followed by a fully connected layer to detect out of vocabulary words. ENN is an optional feature that brings more accuracy and let you leave the system on always, so you dont need to say wake up words. ENN user interface includes these main tabs: Train Sample Link Wrong","title":"ENN"},{"location":"Train-Neural-Network/#enn-train","text":"In Train Tab you can watch the learning procedure of each word. In train Panel, learning loss and test loss is shown for first 4 words in wordlist panel. You can watch other word loss plots by pressing Up/Down arrow keys on keyboard. Hover on each word in word list panel to see how many samples are trained from total samples. Also you can sort the model statistics based on train precision, test precision and loss by clicking relevant table header (to reset the sort method click on ID header). Learned models will be saved in Model directory.","title":"ENN Train"},{"location":"Train-Neural-Network/#parameters","text":"Thread Num: Number of concurrent words to learn. (Be careful to set it lower than your number of CPU cores to prevent windows freeze) Learning rate: Base learning rate for each word to start training. Target Loss: Loss that model is considered learned. Param Num: Number of parameters the model has to learn. True Count: Number of ENN samples in enn/true directory. False Count: Number of ENN samples in enn/false directory. Learned Count: Number of words that their loss become less than target loss. Loop Count: Training for each word takes 200 epoch, if target loss not reached. Then next word's training procedure starts. After all words training finished, program will start from first word and increases loop count. Train Time: Time that program is training words.","title":"Parameters"},{"location":"Train-Neural-Network/#enn-sample-link","text":"In sample link tab all true sample cepstrums are ploted in images. In this way you can find out why training for a word has large loss and not reaches the target loss. By using direction arrow keys you can select then play the wave related to each sample. Also change the word to see its samples. (Train procedure is not stopped while sample link is active)","title":"ENN Sample Link"},{"location":"Train-Neural-Network/#wrong","text":"In training procedure, some samples couldn't be learned, they will be stored in Models/Wrong directory. For each model there is a relevant .wrong file that is filled by all failed samples. In the same way as Sample Link you can watch wrong detected sample cepstrums and here relevant recorded wave. The label for each sample is shown in right bottom corner of its cepstrum.","title":"Wrong"},{"location":"Capture-Audio-Samples/ug/","text":"User Guide A detailed description of ArBade functionalities is discussed in this document. Record Record Status Record Parameters Record Shortcuts Verify Verify Status Verify Parameters Verify Shortcuts Sleep Wrong False Test Enn False Console Record While recording the samples for training the voice recognition engine, you should know the status, parameters and shortcuts related to recording. Record Status Rec : Records your voice Pause : Pause the Recording Procedure Stop : Stop the record and navigate to statistics panel. Req Pause : Requested pause will be commited after recording finished Break : Time to let you read the words before recording started Record Parameters Category : Directories to classify samples you record with different devices. exceptions are unverified , online , sleep , wrong , test , enn and efalse which are used internally by Benjamin. Pause Time : Break time that lets you read the words before record process starts. Num of Words : Specify the number of words for recording samples. Rec Time : Defines the period of recording time. Count : Set this to the total number of samples you want to record in a single round. Focus Word : A displayed set of words will contain the Focus Word . Power : After recording the sample power of the voice will be displayed. Care about this parameter as this will be very low if the recording device has any problem. Time : Shows how much time passed from Rec Time Word : Shows the words you should say while recording Status : Shows recording status Record Shortcuts S : Set Category , unverified and efalse are prohibited. A dialog will be shown and ask for the desired Category . You can create a new Category or change between categories produced in the past. Space : Start or Pause recording. Up/Down : Increase/Decrease Pause Time . Right/Left : Increase/Decrease Rec Time . C : Change count, a dialog will be opened and ask for how many samples would you record. F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . W : Opens a dialog to ask Num of Words . O : Opens selected Category directory. Verify By using Benjamin regularly, many samples will be created as online samples. However, these samples are not labeled correctly. There may be some mistakes among words from a sample. These samples are accumulated in unverified directory and by verifying them, they will be moved to online directory. Verification is done by playing the samples in unverified directory. you can refer to this section to know all status, parameters and shortcuts related to verification. Verify Shortcuts Space : Start or Pause playing. Up/Down : Increase/Decrease Pause Time . F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . O : Opens unverified directory. Z : Press to move the sample from the unverified directory to the wrong directory. R : Changes default decision/action for verifying samples. Copy mode means after the Decide Pause timeout, the sample will be copied to the online directory. In the same way in Delete mode, timeout will cause sample removal. Sleep Verify samples recorded in sleep mode. In this mode listen to the recorded samples, if they contain any true samples press Z to get rid of them. All other samples will automatically moved to the wrong directory and they will be used to train the enn model. Wrong These are verified samples from the sleep directory. They are verified to be wrong samples, not true ones! In this mode, you will be able to review them and check if some samples are moved to this directory by accident. False During generating Enn samples, some of the samples in the train directory will not detect correctly, these samples will be moved to the efalse directory. In this mode, you can listen to these samples and judge whether they are real samples or the wrong ones which you should get rid of them. Test After training on samples, the model is evaluated through test samples. Word error rate (WER) and Sentence error rate (SER) are calculated by predicting test samples. Then false detected samples are listed in this tab and you can listen to them to figure out what went wrong. Enn False BaTool generates enn samples, from both train samples and wrong samples. The enn directory is the destination of this process. Enn files from the train directory are located in enn/true and wrong directory-related files are in enn/false . In the Enn False tab, only false statistics are shown. By clicking the trash icon, all Enn samples will be deleted. Console Training on samples is started by pressing T . After training is finished, a dialog pops up and asks to generate enn samples from audio samples. Neural Network will be trained from these enn samples. When generating Enn Samples is finished, another dialog arises and asks about verifying generated engine false detected samples. Engine false detected samples, abbreviated as efalse samples, are collected in the efalse directory. They are generated after training, and while testing samples in the test directory. You can verify them by switching to False and Test tabs.","title":"User Guide"},{"location":"Capture-Audio-Samples/ug/#user-guide","text":"A detailed description of ArBade functionalities is discussed in this document. Record Record Status Record Parameters Record Shortcuts Verify Verify Status Verify Parameters Verify Shortcuts Sleep Wrong False Test Enn False Console","title":"User Guide"},{"location":"Capture-Audio-Samples/ug/#record","text":"While recording the samples for training the voice recognition engine, you should know the status, parameters and shortcuts related to recording.","title":"Record"},{"location":"Capture-Audio-Samples/ug/#record-status","text":"Rec : Records your voice Pause : Pause the Recording Procedure Stop : Stop the record and navigate to statistics panel. Req Pause : Requested pause will be commited after recording finished Break : Time to let you read the words before recording started","title":"Record Status"},{"location":"Capture-Audio-Samples/ug/#record-parameters","text":"Category : Directories to classify samples you record with different devices. exceptions are unverified , online , sleep , wrong , test , enn and efalse which are used internally by Benjamin. Pause Time : Break time that lets you read the words before record process starts. Num of Words : Specify the number of words for recording samples. Rec Time : Defines the period of recording time. Count : Set this to the total number of samples you want to record in a single round. Focus Word : A displayed set of words will contain the Focus Word . Power : After recording the sample power of the voice will be displayed. Care about this parameter as this will be very low if the recording device has any problem. Time : Shows how much time passed from Rec Time Word : Shows the words you should say while recording Status : Shows recording status","title":"Record Parameters"},{"location":"Capture-Audio-Samples/ug/#record-shortcuts","text":"S : Set Category , unverified and efalse are prohibited. A dialog will be shown and ask for the desired Category . You can create a new Category or change between categories produced in the past. Space : Start or Pause recording. Up/Down : Increase/Decrease Pause Time . Right/Left : Increase/Decrease Rec Time . C : Change count, a dialog will be opened and ask for how many samples would you record. F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . W : Opens a dialog to ask Num of Words . O : Opens selected Category directory.","title":"Record Shortcuts"},{"location":"Capture-Audio-Samples/ug/#verify","text":"By using Benjamin regularly, many samples will be created as online samples. However, these samples are not labeled correctly. There may be some mistakes among words from a sample. These samples are accumulated in unverified directory and by verifying them, they will be moved to online directory. Verification is done by playing the samples in unverified directory. you can refer to this section to know all status, parameters and shortcuts related to verification.","title":"Verify"},{"location":"Capture-Audio-Samples/ug/#verify-shortcuts","text":"Space : Start or Pause playing. Up/Down : Increase/Decrease Pause Time . F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . O : Opens unverified directory. Z : Press to move the sample from the unverified directory to the wrong directory. R : Changes default decision/action for verifying samples. Copy mode means after the Decide Pause timeout, the sample will be copied to the online directory. In the same way in Delete mode, timeout will cause sample removal.","title":"Verify Shortcuts"},{"location":"Capture-Audio-Samples/ug/#sleep","text":"Verify samples recorded in sleep mode. In this mode listen to the recorded samples, if they contain any true samples press Z to get rid of them. All other samples will automatically moved to the wrong directory and they will be used to train the enn model.","title":"Sleep"},{"location":"Capture-Audio-Samples/ug/#wrong","text":"These are verified samples from the sleep directory. They are verified to be wrong samples, not true ones! In this mode, you will be able to review them and check if some samples are moved to this directory by accident.","title":"Wrong"},{"location":"Capture-Audio-Samples/ug/#false","text":"During generating Enn samples, some of the samples in the train directory will not detect correctly, these samples will be moved to the efalse directory. In this mode, you can listen to these samples and judge whether they are real samples or the wrong ones which you should get rid of them.","title":"False"},{"location":"Capture-Audio-Samples/ug/#test","text":"After training on samples, the model is evaluated through test samples. Word error rate (WER) and Sentence error rate (SER) are calculated by predicting test samples. Then false detected samples are listed in this tab and you can listen to them to figure out what went wrong.","title":"Test"},{"location":"Capture-Audio-Samples/ug/#enn-false","text":"BaTool generates enn samples, from both train samples and wrong samples. The enn directory is the destination of this process. Enn files from the train directory are located in enn/true and wrong directory-related files are in enn/false . In the Enn False tab, only false statistics are shown. By clicking the trash icon, all Enn samples will be deleted.","title":"Enn False"},{"location":"Capture-Audio-Samples/ug/#console","text":"Training on samples is started by pressing T . After training is finished, a dialog pops up and asks to generate enn samples from audio samples. Neural Network will be trained from these enn samples. When generating Enn Samples is finished, another dialog arises and asks about verifying generated engine false detected samples. Engine false detected samples, abbreviated as efalse samples, are collected in the efalse directory. They are generated after training, and while testing samples in the test directory. You can verify them by switching to False and Test tabs.","title":"Console"}]}