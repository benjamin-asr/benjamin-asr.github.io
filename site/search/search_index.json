{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Features \uf0c1 Speak Recognition Engine without connection to any cloud or external server. Ultra low latency recognition that can reach down to less than 100ms. Remove the requirement of wake-up word for every command. Enable local training of the model and fine-tune it for individual voices. Provide an environment for recording samples and verifying the recorded audio data. Achieve 99% accuracy thanks to the small set of words and adapt to the user's accent. Offer full customization of the word list and control over the training setup. Provide easy integration with other softwares through DBus (Linux) and Named-Pipe (Windows) platform. Allow voice control interface for Windows 10 and Linux running with custom setup of Awesome-WM and Polybar . Ready to use product without any requirement for customization and coding skill. Origin of Design \uf0c1 Benjamin began as a voice control interface to control a PC without any interaction through hands. numerous other products exist on the market, offering specific application solutions. What sets Benjamin apart from these projects is its tailored design for individuals with handicap to use this system 24/7 to interact with a PC. This requirement stress over highest level of accuracy and focus on decreasing latency as many command and control actions require quick response time. One notable product for comparison is the Google Speech Recognition Engine integrated into YouTube's subtitle generator. This engine prioritizes accuracy across a diverse range of accents found in the general population. However, if user accent is a minority, the accuracy of these off-the-shelf engines may diminish rapidly. Another critical assumption in the YouTube ASR engine is the availability of future voice data ( non causal ), with no stringent requirement on output latency. This drastically alters the architecture of ASR engine design to maximize the accuracy. Benjamin addresses these challenges by decreasing the number of words in the vocabulary and focus on single person's accent rather than general public to achieve same or better accuracy than major ASR engines, while maintaining low latency output.It aims to provide users in need of creating a voice control software a better starting point so hopefully in future we will see more progress in future of robust ASR engines and voice control softwares for this specific application.","title":"Home"},{"location":"#features","text":"Speak Recognition Engine without connection to any cloud or external server. Ultra low latency recognition that can reach down to less than 100ms. Remove the requirement of wake-up word for every command. Enable local training of the model and fine-tune it for individual voices. Provide an environment for recording samples and verifying the recorded audio data. Achieve 99% accuracy thanks to the small set of words and adapt to the user's accent. Offer full customization of the word list and control over the training setup. Provide easy integration with other softwares through DBus (Linux) and Named-Pipe (Windows) platform. Allow voice control interface for Windows 10 and Linux running with custom setup of Awesome-WM and Polybar . Ready to use product without any requirement for customization and coding skill.","title":"Features"},{"location":"#origin-of-design","text":"Benjamin began as a voice control interface to control a PC without any interaction through hands. numerous other products exist on the market, offering specific application solutions. What sets Benjamin apart from these projects is its tailored design for individuals with handicap to use this system 24/7 to interact with a PC. This requirement stress over highest level of accuracy and focus on decreasing latency as many command and control actions require quick response time. One notable product for comparison is the Google Speech Recognition Engine integrated into YouTube's subtitle generator. This engine prioritizes accuracy across a diverse range of accents found in the general population. However, if user accent is a minority, the accuracy of these off-the-shelf engines may diminish rapidly. Another critical assumption in the YouTube ASR engine is the availability of future voice data ( non causal ), with no stringent requirement on output latency. This drastically alters the architecture of ASR engine design to maximize the accuracy. Benjamin addresses these challenges by decreasing the number of words in the vocabulary and focus on single person's accent rather than general public to achieve same or better accuracy than major ASR engines, while maintaining low latency output.It aims to provide users in need of creating a voice control software a better starting point so hopefully in future we will see more progress in future of robust ASR engines and voice control softwares for this specific application.","title":"Origin of Design"},{"location":"Controlling-Keyboard/","text":"Command Action Command Action arch a november n bravo b oscar o catalina c papa p delta d quebec q echo e romeo r fish f sierra s golf g tango t hotel h u u india i vpn v jordan j wake w kilo k eggs x limo l yankee y mike m zed z Command Action Command Action sim Space plus + end end slash / home home canals \\ semi ; edge Menu key period . bracket [] comma , curly {} dash - quote \"\" level = github Caps lock","title":"Controlling Keyboard"},{"location":"Controlling-Mouse/","text":"Command Action Description Mouse Left Left Click Mouse Right Right Click Mouse M Middle Click Mouse Up Scroll Up Mouse Down Scroll Down Mouse P Primary Monitor Mouse S Secondary Monitor Mouse L Primary Monitor Left Side Mouse R Primary Monitor Right Side Mouse U Scroll Up 4 Times Mouse D Scroll Down 4 Times Mouse G Scroll Up 6 Times Mouse H Scroll Down 6 Times","title":"Controlling Mouse"},{"location":"Quick-Start-Guide/","text":"Note Files and directories with names which begin with a dot (for example: .foo.md or .bar/baz.md ) are ignored by MkDocs. This can be overridden with the exclude_docs config .","title":"Quick Start Guide"},{"location":"about/","text":"About \uf0c1 Feel free to contact us by sending email.","title":"About"},{"location":"about/#about","text":"Feel free to contact us by sending email.","title":"About"},{"location":"arbade/","text":"ArBade \uf0c1 Features: Building dataset for voice recognition engine by recording voice samples Handy tool to train and test voice samples Environment to verify online samples generated while using BaTool Verify samples generated in sleep mode to detect while not speeking with voice recognition engine. Review wrong words after verifying sleep samples. Verify triphone engine misclassified samples. Console environment to train on samples. User Guide \uf0c1 Quick Start \uf0c1 ArBade has many tabs, explained in the following. To change tab click or press numbers on keyboard starting from 1. ArBade is a shortcut based application. Shortcuts are listed in the application topbar. To see all shortcuts, press / . First step is to train a model from your voice. Record Samples \uf0c1 specify a category name by pressing S . category name is used to distinguish between speaker or microphone. Start to record by pressing space . Say the words specified between <> while status is Rec . You can pause the Record procedure any time by using space and get out of record panel by pressing Escape . Then Statistics will be updated. Arbitrary name of category. Record list showing the samples recorded. Word list showing how many samples include the specific word. sample count in specific category. Detailed description about record parameters and procedure can be found in the User Guide Train Model \uf0c1 After recording around 10 x Wordlist samples, you are ready to train your model by Pressing T . At any time outside of terminal, by pressing P or clicking on Console tab, you can access the results of running train scripts in terminal. All the train procedure is automatic and you should only wait for the dialog indicating train is finished and now it's ENN samples generation turn. And verifying engine false generated samples. Detailed description about train steps and procedure can be found in User Guide Verification \uf0c1 When you are using Benjamin regularly, samples will be generated when issueing commands or recorded when in sleep mode saying ordinary words. To use these samples, you need to assure that they are matched with the detected words. For verifying these samples you can switch to Verify tab and press space to start verification process. While verifying sleep mode samples, make sure that all words are detected wrong. Verifying If the sample is wrong press Z to delete sample, while playing or at Decide Pause status after voice stopped. By default after playing each sample in unverified category, if there wasn't any key press, the sample will be verified. you can change this behaviour by pressing R . Detailed description about verification parameters and procedure can be found in User Guide Congrats! Now you know the very initial steps to train your model!","title":"ArBade"},{"location":"arbade/#arbade","text":"Features: Building dataset for voice recognition engine by recording voice samples Handy tool to train and test voice samples Environment to verify online samples generated while using BaTool Verify samples generated in sleep mode to detect while not speeking with voice recognition engine. Review wrong words after verifying sleep samples. Verify triphone engine misclassified samples. Console environment to train on samples.","title":"ArBade"},{"location":"arbade/#user-guide","text":"","title":"User Guide"},{"location":"arbade/#quick-start","text":"ArBade has many tabs, explained in the following. To change tab click or press numbers on keyboard starting from 1. ArBade is a shortcut based application. Shortcuts are listed in the application topbar. To see all shortcuts, press / . First step is to train a model from your voice.","title":"Quick Start"},{"location":"arbade/#record-samples","text":"specify a category name by pressing S . category name is used to distinguish between speaker or microphone. Start to record by pressing space . Say the words specified between <> while status is Rec . You can pause the Record procedure any time by using space and get out of record panel by pressing Escape . Then Statistics will be updated. Arbitrary name of category. Record list showing the samples recorded. Word list showing how many samples include the specific word. sample count in specific category. Detailed description about record parameters and procedure can be found in the User Guide","title":"Record Samples"},{"location":"arbade/#train-model","text":"After recording around 10 x Wordlist samples, you are ready to train your model by Pressing T . At any time outside of terminal, by pressing P or clicking on Console tab, you can access the results of running train scripts in terminal. All the train procedure is automatic and you should only wait for the dialog indicating train is finished and now it's ENN samples generation turn. And verifying engine false generated samples. Detailed description about train steps and procedure can be found in User Guide","title":"Train Model"},{"location":"arbade/#verification","text":"When you are using Benjamin regularly, samples will be generated when issueing commands or recorded when in sleep mode saying ordinary words. To use these samples, you need to assure that they are matched with the detected words. For verifying these samples you can switch to Verify tab and press space to start verification process. While verifying sleep mode samples, make sure that all words are detected wrong. Verifying If the sample is wrong press Z to delete sample, while playing or at Decide Pause status after voice stopped. By default after playing each sample in unverified category, if there wasn't any key press, the sample will be verified. you can change this behaviour by pressing R . Detailed description about verification parameters and procedure can be found in User Guide Congrats! Now you know the very initial steps to train your model!","title":"Verification"},{"location":"batool/","text":"BaTool \uf0c1 BaTool is a real-time speech recognition engine, that gets a triphone Kaldi model and do a low latency speech recognition on the data coming from the system default microphone. BaTool Conf \uf0c1 Batool is configurable via conf file next to BaTool application. It has 4 main sections to configure: Model Section: \uf0c1 This section defines the location of Kaldi model files. The addresses are relative to where BaTool application exists. ; Model path [model] fst = \"Model/HCLG.fst\" mdl = \"Model/final.oalimdl\" word = \"Model/words.txt\" cmvn = \"Model/global_cmvn.stats\" Decoder Section: \uf0c1 Kaldi related decoder settings. max_active = 900 min_active = 200 train_max = 5 ac_scale = 0.05 min_sil = 20 train_max : Maximum number of same samples for later training. min_sil : Minimum silence before detection. This value directly connected with accuracy and latency. Captain Section: \uf0c1 ; Threshold for detecting words [captain] hard_threshold = 0.35 Miscellaneous Section: \uf0c1 ; Miscellaneous parameters [misc] mic = \"Sennheiser\" channel = \"com_binaee_rebound\"","title":"BaTool"},{"location":"batool/#batool","text":"BaTool is a real-time speech recognition engine, that gets a triphone Kaldi model and do a low latency speech recognition on the data coming from the system default microphone.","title":"BaTool"},{"location":"batool/#batool-conf","text":"Batool is configurable via conf file next to BaTool application. It has 4 main sections to configure:","title":"BaTool Conf"},{"location":"batool/#model-section","text":"This section defines the location of Kaldi model files. The addresses are relative to where BaTool application exists. ; Model path [model] fst = \"Model/HCLG.fst\" mdl = \"Model/final.oalimdl\" word = \"Model/words.txt\" cmvn = \"Model/global_cmvn.stats\"","title":"Model Section:"},{"location":"batool/#decoder-section","text":"Kaldi related decoder settings. max_active = 900 min_active = 200 train_max = 5 ac_scale = 0.05 min_sil = 20 train_max : Maximum number of same samples for later training. min_sil : Minimum silence before detection. This value directly connected with accuracy and latency.","title":"Decoder Section:"},{"location":"batool/#captain-section","text":"; Threshold for detecting words [captain] hard_threshold = 0.35","title":"Captain Section:"},{"location":"batool/#miscellaneous-section","text":"; Miscellaneous parameters [misc] mic = \"Sennheiser\" channel = \"com_binaee_rebound\"","title":"Miscellaneous Section:"},{"location":"chess/","text":"Chess \uf0c1 In the following image you can see chess in action. Chess supports following commands: Kick : Normal left click button Side : Right click button Drag : Drag with left click between two points. System Sierra : Take screenshot between two points and put it in clipboard Comments : Open chess on second monitor","title":"Chess"},{"location":"chess/#chess","text":"In the following image you can see chess in action. Chess supports following commands: Kick : Normal left click button Side : Right click button Drag : Drag with left click between two points. System Sierra : Take screenshot between two points and put it in clipboard Comments : Open chess on second monitor","title":"Chess"},{"location":"enn/","text":"ENN \uf0c1 ENN generates neural network model from ENN samples. ENN samples are cepstrums that were normalized and aligned to a single word saved as a simple 40x40 binary array. we feed this to a convolutional neural network followed by a fully connected layer to detect out of vocabulary words. ENN is an optional feature that brings more accuracy and let you leave the system on always, so you dont need to say wake up words. ENN user interface includes these main tabs: Train Sample Link Wrong ENN Train \uf0c1 In Train Tab you can watch the learning procedure of each word. In train Panel, learning loss and test loss is shown for first 4 words in wordlist panel. You can watch other word loss plots by pressing Up/Down arrow keys on keyboard. Hover on each word in word list panel to see how many samples are trained from total samples. Also you can sort the model statistics based on train precision, test precision and loss by clicking relevant table header (to reset the sort method click on ID header). Learned models will be saved in Model directory. Parameters \uf0c1 Thread Num: Number of concurrent words to learn. (Be careful to set it lower than your number of CPU cores to prevent windows freeze) Learning rate: Base learning rate for each word to start training. Target Loss: Loss that model is considered learned. Param Num: Number of parameters the model has to learn. True Count: Number of ENN samples in enn/true directory. False Count: Number of ENN samples in enn/false directory. Learned Count: Number of words that their loss become less than target loss. Loop Count: Training for each word takes 200 epoch, if target loss not reached. Then next word's training procedure starts. After all words training finished, program will start from first word and increases loop count. Train Time: Time that program is training words. ENN Sample Link \uf0c1 In sample link tab all true sample cepstrums are ploted in images. In this way you can find out why training for a word has large loss and not reaches the target loss. By using direction arrow keys you can select then play the wave related to each sample. Also change the word to see its samples. (Train procedure is not stopped while sample link is active) Wrong \uf0c1 In training procedure, some samples couldn't be learned, they will be stored in Models/Wrong directory. For each model there is a relevant .wrong file that is filled by all failed samples. In the same way as Sample Link you can watch wrong detected sample cepstrums and here relevant recorded wave. The label for each sample is shown in right bottom corner of its cepstrum.","title":"ENN"},{"location":"enn/#enn","text":"ENN generates neural network model from ENN samples. ENN samples are cepstrums that were normalized and aligned to a single word saved as a simple 40x40 binary array. we feed this to a convolutional neural network followed by a fully connected layer to detect out of vocabulary words. ENN is an optional feature that brings more accuracy and let you leave the system on always, so you dont need to say wake up words. ENN user interface includes these main tabs: Train Sample Link Wrong","title":"ENN"},{"location":"enn/#enn-train","text":"In Train Tab you can watch the learning procedure of each word. In train Panel, learning loss and test loss is shown for first 4 words in wordlist panel. You can watch other word loss plots by pressing Up/Down arrow keys on keyboard. Hover on each word in word list panel to see how many samples are trained from total samples. Also you can sort the model statistics based on train precision, test precision and loss by clicking relevant table header (to reset the sort method click on ID header). Learned models will be saved in Model directory.","title":"ENN Train"},{"location":"enn/#parameters","text":"Thread Num: Number of concurrent words to learn. (Be careful to set it lower than your number of CPU cores to prevent windows freeze) Learning rate: Base learning rate for each word to start training. Target Loss: Loss that model is considered learned. Param Num: Number of parameters the model has to learn. True Count: Number of ENN samples in enn/true directory. False Count: Number of ENN samples in enn/false directory. Learned Count: Number of words that their loss become less than target loss. Loop Count: Training for each word takes 200 epoch, if target loss not reached. Then next word's training procedure starts. After all words training finished, program will start from first word and increases loop count. Train Time: Time that program is training words.","title":"Parameters"},{"location":"enn/#enn-sample-link","text":"In sample link tab all true sample cepstrums are ploted in images. In this way you can find out why training for a word has large loss and not reaches the target loss. By using direction arrow keys you can select then play the wave related to each sample. Also change the word to see its samples. (Train procedure is not stopped while sample link is active)","title":"ENN Sample Link"},{"location":"enn/#wrong","text":"In training procedure, some samples couldn't be learned, they will be stored in Models/Wrong directory. For each model there is a relevant .wrong file that is filled by all failed samples. In the same way as Sample Link you can watch wrong detected sample cepstrums and here relevant recorded wave. The label for each sample is shown in right bottom corner of its cepstrum.","title":"Wrong"},{"location":"installation/","text":"Note Files and directories with names which begin with a dot (for example: .foo.md or .bar/baz.md ) are ignored by MkDocs. This can be overridden with the exclude_docs config .","title":"Installation"},{"location":"mom/","text":"Mom \uf0c1 Mom is like PolyBar , it manages different workspace, shows system status and BaTool detection output. Mom is named after the fact that it will spawn all the child applications (BaTool, Chess, Rebound). Mom reads BaTool detection from Benjamin/Mom/Labels with PolyBar Application format . Mom has several widgets: Workspaces: you can switch between 6 workspaces showed with different icons. Word detection from BaTool and ENN . Date and time Music widget: Used to pause/play music. Also go to next/previous music. CPU usage Speaker: By clicking on this icon you can alter between speaker and headphone. By scrolling you can increase/decrease the volume. Focused application System status: Shows if system is running or sleeping or halted. Color of detected word is set by ENN application and sorted from best detection accuracy to worst: Best Good Lowest Confidence Wrong","title":"Mom"},{"location":"mom/#mom","text":"Mom is like PolyBar , it manages different workspace, shows system status and BaTool detection output. Mom is named after the fact that it will spawn all the child applications (BaTool, Chess, Rebound). Mom reads BaTool detection from Benjamin/Mom/Labels with PolyBar Application format . Mom has several widgets: Workspaces: you can switch between 6 workspaces showed with different icons. Word detection from BaTool and ENN . Date and time Music widget: Used to pause/play music. Also go to next/previous music. CPU usage Speaker: By clicking on this icon you can alter between speaker and headphone. By scrolling you can increase/decrease the volume. Focused application System status: Shows if system is running or sleeping or halted. Color of detected word is set by ENN application and sorted from best detection accuracy to worst: Best Good Lowest Confidence Wrong","title":"Mom"},{"location":"rebound/","text":"Rebound \uf0c1","title":"Rebound"},{"location":"rebound/#rebound","text":"","title":"Rebound"},{"location":"arbade/ug/","text":"User Guide \uf0c1 A detailed description of ArBade functionalities is discussed in this document. Record Record Status Record Parameters Record Shortcuts Verify Verify Status Verify Parameters Verify Shortcuts Sleep Wrong False Test Enn False Console Record \uf0c1 While recording the samples for training the voice recognition engine, you should know the status, parameters and shortcuts related to recording. Record Status \uf0c1 Rec : Records your voice Pause : Pause the Recording Procedure Stop : Stop the record and navigate to statistics panel. Req Pause : Requested pause will be commited after recording finished Break : Time to let you read the words before recording started Record Parameters \uf0c1 Category : Directories to classify samples you record with different devices. exceptions are unverified , online , sleep , wrong , test , enn and efalse which are used internally by Benjamin. Pause Time : Break time that lets you read the words before record process starts. Num of Words : Specify the number of words for recording samples. Rec Time : Defines the period of recording time. Count : Set this to the total number of samples you want to record in a single round. Focus Word : A displayed set of words will contain the Focus Word . Power : After recording the sample power of the voice will be displayed. Care about this parameter as this will be very low if the recording device has any problem. Time : Shows how much time passed from Rec Time Word : Shows the words you should say while recording Status : Shows recording status Record Shortcuts \uf0c1 S : Set Category , unverified and efalse are prohibited. A dialog will be shown and ask for the desired Category . You can create a new Category or change between categories produced in the past. Space : Start or Pause recording. Up/Down : Increase/Decrease Pause Time . Right/Left : Increase/Decrease Rec Time . C : Change count, a dialog will be opened and ask for how many samples would you record. F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . W : Opens a dialog to ask Num of Words . O : Opens selected Category directory. Verify \uf0c1 By using Benjamin regularly, many samples will be created as online samples. However, these samples are not labeled correctly. There may be some mistakes among words from a sample. These samples are accumulated in unverified directory and by verifying them, they will be moved to online directory. Verification is done by playing the samples in unverified directory. you can refer to this section to know all status, parameters and shortcuts related to verification. Verify Shortcuts \uf0c1 Space : Start or Pause playing. Up/Down : Increase/Decrease Pause Time . F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . O : Opens unverified directory. Z : Press to move the sample from the unverified directory to the wrong directory. R : Changes default decision/action for verifying samples. Copy mode means after the Decide Pause timeout, the sample will be copied to the online directory. In the same way in Delete mode, timeout will cause sample removal. Sleep \uf0c1 Verify samples recorded in sleep mode. In this mode listen to the recorded samples, if they contain any true samples press Z to get rid of them. All other samples will automatically moved to the wrong directory and they will be used to train the enn model. Wrong \uf0c1 These are verified samples from the sleep directory. They are verified to be wrong samples, not true ones! In this mode, you will be able to review them and check if some samples are moved to this directory by accident. False \uf0c1 During generating Enn samples, some of the samples in the train directory will not detect correctly, these samples will be moved to the efalse directory. In this mode, you can listen to these samples and judge whether they are real samples or the wrong ones which you should get rid of them. Test \uf0c1 After training on samples, the model is evaluated through test samples. Word error rate (WER) and Sentence error rate (SER) are calculated by predicting test samples. Then false detected samples are listed in this tab and you can listen to them to figure out what went wrong. Enn False \uf0c1 BaTool generates enn samples, from both train samples and wrong samples. The enn directory is the destination of this process. Enn files from the train directory are located in enn/true and wrong directory-related files are in enn/false . In the Enn False tab, only false statistics are shown. By clicking the trash icon, all Enn samples will be deleted. Console \uf0c1 Training on samples is started by pressing T . After training is finished, a dialog pops up and asks to generate enn samples from audio samples. Neural Network will be trained from these enn samples. When generating Enn Samples is finished, another dialog arises and asks about verifying generated engine false detected samples. Engine false detected samples, abbreviated as efalse samples, are collected in the efalse directory. They are generated after training, and while testing samples in the test directory. You can verify them by switching to False and Test tabs.","title":"User Guide"},{"location":"arbade/ug/#user-guide","text":"A detailed description of ArBade functionalities is discussed in this document. Record Record Status Record Parameters Record Shortcuts Verify Verify Status Verify Parameters Verify Shortcuts Sleep Wrong False Test Enn False Console","title":"User Guide"},{"location":"arbade/ug/#record","text":"While recording the samples for training the voice recognition engine, you should know the status, parameters and shortcuts related to recording.","title":"Record"},{"location":"arbade/ug/#record-status","text":"Rec : Records your voice Pause : Pause the Recording Procedure Stop : Stop the record and navigate to statistics panel. Req Pause : Requested pause will be commited after recording finished Break : Time to let you read the words before recording started","title":"Record Status"},{"location":"arbade/ug/#record-parameters","text":"Category : Directories to classify samples you record with different devices. exceptions are unverified , online , sleep , wrong , test , enn and efalse which are used internally by Benjamin. Pause Time : Break time that lets you read the words before record process starts. Num of Words : Specify the number of words for recording samples. Rec Time : Defines the period of recording time. Count : Set this to the total number of samples you want to record in a single round. Focus Word : A displayed set of words will contain the Focus Word . Power : After recording the sample power of the voice will be displayed. Care about this parameter as this will be very low if the recording device has any problem. Time : Shows how much time passed from Rec Time Word : Shows the words you should say while recording Status : Shows recording status","title":"Record Parameters"},{"location":"arbade/ug/#record-shortcuts","text":"S : Set Category , unverified and efalse are prohibited. A dialog will be shown and ask for the desired Category . You can create a new Category or change between categories produced in the past. Space : Start or Pause recording. Up/Down : Increase/Decrease Pause Time . Right/Left : Increase/Decrease Rec Time . C : Change count, a dialog will be opened and ask for how many samples would you record. F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . W : Opens a dialog to ask Num of Words . O : Opens selected Category directory.","title":"Record Shortcuts"},{"location":"arbade/ug/#verify","text":"By using Benjamin regularly, many samples will be created as online samples. However, these samples are not labeled correctly. There may be some mistakes among words from a sample. These samples are accumulated in unverified directory and by verifying them, they will be moved to online directory. Verification is done by playing the samples in unverified directory. you can refer to this section to know all status, parameters and shortcuts related to verification.","title":"Verify"},{"location":"arbade/ug/#verify-shortcuts","text":"Space : Start or Pause playing. Up/Down : Increase/Decrease Pause Time . F : Set Focus Word , then the displayed words collection will contain Focus Word . A dialog will be opened and ask for the id of Focus Word . O : Opens unverified directory. Z : Press to move the sample from the unverified directory to the wrong directory. R : Changes default decision/action for verifying samples. Copy mode means after the Decide Pause timeout, the sample will be copied to the online directory. In the same way in Delete mode, timeout will cause sample removal.","title":"Verify Shortcuts"},{"location":"arbade/ug/#sleep","text":"Verify samples recorded in sleep mode. In this mode listen to the recorded samples, if they contain any true samples press Z to get rid of them. All other samples will automatically moved to the wrong directory and they will be used to train the enn model.","title":"Sleep"},{"location":"arbade/ug/#wrong","text":"These are verified samples from the sleep directory. They are verified to be wrong samples, not true ones! In this mode, you will be able to review them and check if some samples are moved to this directory by accident.","title":"Wrong"},{"location":"arbade/ug/#false","text":"During generating Enn samples, some of the samples in the train directory will not detect correctly, these samples will be moved to the efalse directory. In this mode, you can listen to these samples and judge whether they are real samples or the wrong ones which you should get rid of them.","title":"False"},{"location":"arbade/ug/#test","text":"After training on samples, the model is evaluated through test samples. Word error rate (WER) and Sentence error rate (SER) are calculated by predicting test samples. Then false detected samples are listed in this tab and you can listen to them to figure out what went wrong.","title":"Test"},{"location":"arbade/ug/#enn-false","text":"BaTool generates enn samples, from both train samples and wrong samples. The enn directory is the destination of this process. Enn files from the train directory are located in enn/true and wrong directory-related files are in enn/false . In the Enn False tab, only false statistics are shown. By clicking the trash icon, all Enn samples will be deleted.","title":"Enn False"},{"location":"arbade/ug/#console","text":"Training on samples is started by pressing T . After training is finished, a dialog pops up and asks to generate enn samples from audio samples. Neural Network will be trained from these enn samples. When generating Enn Samples is finished, another dialog arises and asks about verifying generated engine false detected samples. Engine false detected samples, abbreviated as efalse samples, are collected in the efalse directory. They are generated after training, and while testing samples in the test directory. You can verify them by switching to False and Test tabs.","title":"Console"}]}